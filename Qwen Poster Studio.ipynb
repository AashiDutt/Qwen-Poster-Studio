{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Run this code on a A100 GPU"
      ],
      "metadata": {
        "id": "Ra6LrxLz9eOW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZz27CI-9PNJ"
      },
      "outputs": [],
      "source": [
        "!pip -q install --upgrade pip\n",
        "!pip -q install git+https://github.com/huggingface/diffusers\n",
        "!pip -q install git+https://github.com/huggingface/transformers accelerate\n",
        "!pip -q install gradio pillow safetensors sentencepiece bitsandbytes qwen-vl-utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import random\n",
        "import psutil\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "def mem(tag=\"\"):\n",
        "    ram_gb = psutil.virtual_memory().used / 1e9\n",
        "    if torch.cuda.is_available():\n",
        "        v_alloc = torch.cuda.memory_allocated() / 1e9\n",
        "        v_res   = torch.cuda.memory_reserved() / 1e9\n",
        "        print(f\"[{tag}] RAM={ram_gb:.1f}GB | VRAM alloc={v_alloc:.1f}GB reserved={v_res:.1f}GB\")\n",
        "    else:\n",
        "        print(f\"[{tag}] RAM={ram_gb:.1f}GB | CUDA unavailable\")\n",
        "\n",
        "def cleanup(tag=\"cleanup\"):\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    mem(tag)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DTYPE = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
        "print(\"DEVICE:\", DEVICE, \"| DTYPE:\", DTYPE)\n",
        "if DEVICE == \"cuda\":\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "cleanup(\"startup\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Presets (platform sizes)\n",
        "# ---------------------------\n",
        "ASPECT_PRESETS = {\n",
        "    \"Instagram Post (1:1) — 768×768\": (768, 768),\n",
        "    \"Instagram Story (9:16) — 768×1344\": (768, 1344),\n",
        "    \"Banner (16:9) — 1024×576\": (1024, 576),\n",
        "    \"Poster (3:4) — 832×1104\": (832, 1104),\n",
        "    \"1:1 — 1328×1328 (hi-res)\": (1328, 1328),\n",
        "    \"9:16 — 928×1664 (hi-res)\": (928, 1664),\n",
        "    \"16:9 — 1664×928 (hi-res)\": (1664, 928),\n",
        "    \"3:4 — 1104×1472 (hi-res)\": (1104, 1472),\n",
        "    \"4:3 — 1472×1104 (hi-res)\": (1472, 1104),\n",
        "}\n",
        "\n",
        "DEFAULT_NEG = (\n",
        "    \"low resolution, blurry, jpeg artifacts, messy layout, \"\n",
        "    \"distorted text, misspellings, gibberish letters, watermark, logo\"\n",
        ")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Step A: Draft -> Brief (VL)\n",
        "# ---------------------------\n",
        "def describe_draft_image(draft_pil: Image.Image, language: str = \"English\") -> str:\n",
        "    \"\"\"\n",
        "    Loads Qwen2.5-VL-3B-Instruct in 4-bit, creates a design brief, then unloads the model.\n",
        "    RAM-safe: model exists only during this function call.\n",
        "    \"\"\"\n",
        "    from transformers import AutoProcessor, BitsAndBytesConfig, Qwen2_5_VLForConditionalGeneration\n",
        "    from qwen_vl_utils import process_vision_info\n",
        "\n",
        "    cleanup(\"before VL load\")\n",
        "\n",
        "    if DEVICE != \"cuda\":\n",
        "        raise RuntimeError(\"VL description on CPU will be too slow / RAM heavy. Use GPU.\")\n",
        "    bnb_cfg = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "\n",
        "\n",
        "    vl_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "        \"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
        "        quantization_config=bnb_cfg,\n",
        "        device_map={\"\": 0},\n",
        "        low_cpu_mem_usage=True,\n",
        "        torch_dtype=\"auto\",\n",
        "    )\n",
        "    vl_processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
        "\n",
        "    mem(\"after VL load\")\n",
        "\n",
        "    img = draft_pil.convert(\"RGB\")\n",
        "    img.thumbnail((1024, 1024))\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a senior creative director. Analyze the uploaded poster draft.\n",
        "\n",
        "Return a concise, usable design brief in {language}.\n",
        "Return exactly these sections:\n",
        "- Layout:\n",
        "- Style:\n",
        "- Color palette:\n",
        "- Typography:\n",
        "- Keep:\n",
        "- Improve:\n",
        "- Notes:\n",
        "\n",
        "Do NOT invent brand logos or copyrighted slogans.\n",
        "Be concrete (grid, margins, hierarchy, spacing).\n",
        "\"\"\".strip()\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": img},\n",
        "                {\"type\": \"text\", \"text\": prompt},\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    text = vl_processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    image_inputs, video_inputs = process_vision_info(messages)\n",
        "    inputs = vl_processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        videos=video_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "\n",
        "    out = vl_model.generate(**inputs, max_new_tokens=220)\n",
        "    brief = vl_processor.batch_decode(out, skip_special_tokens=True)[0].strip()\n",
        "    del vl_model, vl_processor, inputs, out\n",
        "    cleanup(\"after VL unload\")\n",
        "\n",
        "    return brief\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Step B: Brief + product info -> Prompt\n",
        "# ---------------------------\n",
        "def build_final_prompt(\n",
        "    product_name: str,\n",
        "    product_desc: str,\n",
        "    offer: str,\n",
        "    price: str,\n",
        "    cta: str,\n",
        "    benefits_text: str,\n",
        "    tone: str,\n",
        "    style_keywords: str,\n",
        "    draft_brief: str | None,\n",
        "    language: str,\n",
        ") -> str:\n",
        "    brief_block = f\"\\n\\nDRAFT-BASED DESIGN BRIEF:\\n{draft_brief}\\n\" if draft_brief else \"\"\n",
        "    return f\"\"\"\n",
        "Create a high-converting e-commerce promotional poster in {language}. Clean grid, strong hierarchy.\n",
        "\n",
        "- Name: \"{product_name}\"\n",
        "- Description: \"{product_desc}\"\n",
        "- Offer headline (exact): \"{offer}\"\n",
        "- Price (exact): \"{price}\"\n",
        "- CTA button text (exact): \"{cta}\"\n",
        "- Benefits (use these exact phrases, no typos):\n",
        "{benefits_text}\n",
        "\n",
        "- Tone: {tone}\n",
        "- Style keywords: {style_keywords}\n",
        "\n",
        "- Text must be legible and correctly spelled.\n",
        "- No extra words, no fake prices, no random letters.\n",
        "- Align to a neat grid with consistent margins.\n",
        "\n",
        "{brief_block}\n",
        "\n",
        "Output: premium, realistic lighting, clean composition, readable typography.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Step C: Generate Poster (T2I)\n",
        "# ---------------------------\n",
        "from diffusers import QwenImagePipeline\n",
        "\n",
        "def load_t2i_pipeline():\n",
        "    cleanup(\"before T2I load\")\n",
        "\n",
        "    t2i = QwenImagePipeline.from_pretrained(\n",
        "    \"Qwen/Qwen-Image-2512\",\n",
        "    torch_dtype=DTYPE,\n",
        "    low_cpu_mem_usage=True,\n",
        "    use_safetensors=True,\n",
        "    ).to(\"cuda\", dtype=DTYPE)\n",
        "    if getattr(t2i, \"vae\", None) is not None:\n",
        "        t2i.vae.to(dtype=torch.float32)\n",
        "        try:\n",
        "            t2i.vae.enable_tiling()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    mem(\"after T2I load\")\n",
        "    return t2i\n",
        "\n",
        "t2i = load_t2i_pipeline()\n",
        "\n",
        "def generate_poster(\n",
        "    prompt: str,\n",
        "    negative_prompt: str,\n",
        "    preset_name: str,\n",
        "    steps: int,\n",
        "    true_cfg_scale: float,\n",
        "    seed: int,\n",
        "):\n",
        "    w, h = ASPECT_PRESETS[preset_name]\n",
        "    gen = torch.Generator(device=DEVICE).manual_seed(int(seed))\n",
        "\n",
        "    img = t2i(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        width=int(w),\n",
        "        height=int(h),\n",
        "        num_inference_steps=int(steps),\n",
        "        true_cfg_scale=float(true_cfg_scale),\n",
        "        generator=gen,\n",
        "    ).images[0]\n",
        "    return img"
      ],
      "metadata": {
        "id": "mjWqgqiS9UVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 6) Gradio UI\n",
        "# ---------------------------\n",
        "import gradio as gr\n",
        "\n",
        "def run_pipeline(\n",
        "    draft_img,\n",
        "    use_draft_brief,\n",
        "    platform_preset,\n",
        "    product_name,\n",
        "    product_desc,\n",
        "    offer,\n",
        "    price,\n",
        "    cta,\n",
        "    benefits,\n",
        "    tone,\n",
        "    style_keywords,\n",
        "    language,\n",
        "    negative_prompt,\n",
        "    steps,\n",
        "    true_cfg_scale,\n",
        "    seed,\n",
        "):\n",
        "    if seed is None or int(seed) < 0:\n",
        "        seed = random.randint(0, 2**31 - 1)\n",
        "    else:\n",
        "        seed = int(seed)\n",
        "    brief = None\n",
        "    if use_draft_brief:\n",
        "        if draft_img is None:\n",
        "            raise gr.Error(\"You enabled 'Use draft brief' but did not upload an image.\")\n",
        "        draft_pil = Image.fromarray(draft_img).convert(\"RGB\")\n",
        "        brief = describe_draft_image(draft_pil, language=language)\n",
        "    final_prompt = build_final_prompt(\n",
        "        product_name=product_name,\n",
        "        product_desc=product_desc,\n",
        "        offer=offer,\n",
        "        price=price,\n",
        "        cta=cta,\n",
        "        benefits_text=benefits,\n",
        "        tone=tone,\n",
        "        style_keywords=style_keywords,\n",
        "        draft_brief=brief,\n",
        "        language=language,\n",
        "    )\n",
        "\n",
        "    out_img = generate_poster(\n",
        "        prompt=final_prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        preset_name=platform_preset,\n",
        "        steps=int(steps),\n",
        "        true_cfg_scale=float(true_cfg_scale),\n",
        "        seed=seed,\n",
        "    )\n",
        "\n",
        "    return brief or \"(draft brief disabled)\", final_prompt, out_img\n",
        "\n",
        "with gr.Blocks(title=\"Qwen Poster Studio\") as demo:\n",
        "    gr.Markdown(\"## Qwen Poster Studio\")\n",
        "    gr.Markdown(\n",
        "        \"- Uses **Qwen2.5-VL 4-bit** only temporarily to extract a design brief, then unloads it.\\n\"\n",
        "        \"- Keeps **Qwen-Image-2512** loaded on GPU for repeated generations.\\n\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            draft = gr.Image(label=\"Upload rough draft poster (optional)\", type=\"numpy\")\n",
        "            use_draft = gr.Checkbox(value=True, label=\"Use draft → design brief (loads VL briefly, then unloads)\")\n",
        "\n",
        "            platform = gr.Dropdown(\n",
        "                choices=list(ASPECT_PRESETS.keys()),\n",
        "                value=\"Instagram Post (1:1) — 768×768\",\n",
        "                label=\"Platform preset (aspect ratio / size)\"\n",
        "            )\n",
        "\n",
        "            product_name = gr.Textbox(value=\"RÅSKOG Utility Cart\", label=\"Product name\")\n",
        "            product_desc = gr.Textbox(value=\"Compact rolling cart for small spaces. Durable metal frame.\", lines=2, label=\"Product description\")\n",
        "            offer = gr.Textbox(value=\"NEW YEAR SALE — 20% OFF\", label=\"Offer headline (exact)\")\n",
        "            price = gr.Textbox(value=\"$29.99\", label=\"Price (exact)\")\n",
        "            cta = gr.Textbox(value=\"Shop now\", label=\"CTA button text (exact)\")\n",
        "            benefits = gr.Textbox(value=\"- Compact\\n- Easy to move\\n- Fits small spaces\", lines=4, label=\"Benefits (exact phrases)\")\n",
        "\n",
        "            tone = gr.Dropdown([\"Premium\", \"Minimal\", \"Bold\", \"Playful\", \"Tech\"], value=\"Premium\", label=\"Tone\")\n",
        "            style = gr.Textbox(value=\"Scandinavian minimal, clean grid, soft warm lighting, premium product photography\", label=\"Style keywords\")\n",
        "            language = gr.Dropdown([\"English\", \"中文\"], value=\"English\", label=\"Language\")\n",
        "\n",
        "            negative = gr.Textbox(value=DEFAULT_NEG, label=\"Negative prompt\", lines=2)\n",
        "\n",
        "            with gr.Row():\n",
        "                steps = gr.Slider(10, 60, value=25, step=1, label=\"Steps\")\n",
        "                cfg = gr.Slider(1.0, 8.0, value=4.0, step=0.1, label=\"true_cfg_scale\")\n",
        "\n",
        "            seed = gr.Number(value=-1, precision=0, label=\"Seed (-1 = random)\")\n",
        "            btn = gr.Button(\"Generate\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            brief_out = gr.Textbox(label=\"Draft-based design brief\", lines=10)\n",
        "            prompt_out = gr.Textbox(label=\"Final prompt sent to Qwen-Image-2512\", lines=10)\n",
        "            out_img = gr.Image(label=\"Output poster\")\n",
        "\n",
        "    btn.click(\n",
        "        fn=run_pipeline,\n",
        "        inputs=[\n",
        "            draft, use_draft, platform,\n",
        "            product_name, product_desc, offer, price, cta, benefits,\n",
        "            tone, style, language,\n",
        "            negative, steps, cfg, seed\n",
        "        ],\n",
        "        outputs=[brief_out, prompt_out, out_img]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug = True)\n"
      ],
      "metadata": {
        "id": "PjCLU8HT9Wr7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}